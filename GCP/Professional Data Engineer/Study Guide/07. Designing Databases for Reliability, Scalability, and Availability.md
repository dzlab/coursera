# Chapter 7: Designing Databases for Reliability, Scalability, and Availability

## Exam Essentials

**Understand Cloud Bigtable is a nonrelational database based on a sparse three-dimensional map.** The three dimensions are rows, columns, and cells. When you create a Cloud Bigtable instance, you specify a number of type of nodes. These nodes manage metadata about the data stored in the Cloud Bigtable database, whereas the actual data is stored outside of the nodes on the Colossus filesystem. Within the Colossus filesystem, data is organized into sorted string tables, or SSTables, which are called tablets.

**Understand how to design row-keys in Cloud Bigtable.** In general, it is best to avoid monotonically increasing values or lexicographically close strings at the beginning of keys. When a using a multitenant Cloud Bigtable database, it is a good practice to use a tenant prefix in the row-key. String identifiers, such as a customer ID or a sensor ID, are good candidates for a row-key. Timestamps may be used as part of a row-key, but they should not be the entire row-key or the start of the row-key. Moving timestamps from the front of a row-key so that another attribute is the first part of the row-key is an example of field promotion. In general, it is a good practice to promote, or move toward the front of the key, values that are highly varied. Another way to avoid hotspots is to use salting.

**Know how to use tall and narrow tables for time-series databases.** Keep names short; this reduces the size of metadata since names are stored along with data values. Store few events within each row, ideally only one event per row; this makes querying easier. Also, storing multiple events increases the chance of exceeding maximum recommended row sizes. Design row-keys for looking up a single value or a range of values. Range scans are common in time-series analysis. Keep in mind that there is only one index on Cloud Bigtable tables.

**Know when to use interleaved tables in Cloud Spanner.** Use interleaved tables with a parent-child relationship in which parent data is stored with child data. This makes retrieving data from both tables simultaneously more efficient than if the data were stored separately and is especially helpful when performing joins. Since the data from both tables is co-located, the database has to perform fewer seeks to get all the needed data.

**Know how to avoid hotspots by designing primary keys properly.** Monotonically increasing keys can cause read and write operations to happen in few servers simultaneously instead of being evenly distributed across all servers. Options for keys include using the hash of a natural key; swapping the order of columns in keys to promote higher-cardinality attributes; using a universally unique identifier (UUID), specifically version 4 or later; and using bit-reverse sequential values.

**Know the differences between primary and secondary indexes.** Primary indexes are created automatically on the primary key. Secondary indexes are explicitly created using the CREATE INDEX command. Secondary indexes are useful when filtering in a query using a WHERE clause. If the column referenced in the WHERE clause is indexed, the index can be used for filtering rather than scanning the full table and then filtering. Secondary indexes are also useful when you need to return rows in a sort order other than the primary key order. When a secondary index is created, the index will store all primary key columns from the base table, all columns included in the index, and any additional columns specified in a STORING clause.

**Understand the organizational structure of BigQuery databases.** Projects are the high- level structure used to organize the use of GCP services and resources. Datasets exist within a project and are containers for tables and views. Access to tables and views are defined at the dataset level. Tables are collections of rows and columns stored in a columnar format, known as Capacitor format, which is designed to support compression and execution optimizations.

**Understand how to denormalize data in BigQuery using nested and repeated fields.** Denormalizing in BigQuery can be done with nested and repeated columns. A column that contains nested and repeated data is defined as a RECORD datatype and is accessed as a STRUCT in SQL. BigQuery supports up to 15 levels of nested STRUCTs.

**Know when and why to use partitioning and clustering in BigQuery.** Partitioning is the process of dividing tables into segments called partitions. BigQuery has three partition types: ingestion time partitioned tables, timestamp partitioned tables, and integer range partitioned tables. In BigQuery, clustering is the ordering of data in its stored format. Clustering is supported only on partitioned tables and is used when filters or aggregations are frequently used.

**Understand the different kinds of queries in BigQuery.** BigQuery supports two types of queries: interactive and batch queries. Interactive queries are executed immediately, whereas batch queries are queued and run when resources are available. The advantage of using these batch queries is that resources are drawn from a shared resource pool and batch queries do not count toward the concurrent rate limit, which is 100 concurrent queries. Queries are run as jobs, similar to jobs run to load and export data.

**Know that BigQuery can access external data without you having to import it into BigQuery first.** BigQuery can access data in external sources, known as federated sources. Instead of first loading data into BigQuery, you can create a reference to an external source. External sources can be Cloud Bigtable, Cloud Storage, and Google Drive. When accessing external data, you can create either permanent or temporary external tables. Permanent tables are those created in a dataset and linked to an external source. Temporary tables are useful for one-time operations, such as loading data into a data warehouse.

**Know that BigQuery ML supports machine learning in BigQuery using SQL.** BigQuery extends standard SQL with the addition of machine learning functionality. This allows BigQuery users to build machine learning models in BigQuery rather than programming models in Python, R, Java, or other programming languages outside of BigQuery.

## Review Questions
You can find the answers in the appendix.
**1.** You are investigating long latencies in Cloud Bigtable query response times. Most queries finish in less than 20 ms, but the 99th percentile queries can take up to 400 ms. You examine a Key Visualizer heatmap and see two areas with bright colors indicating hotspots. What could be causing those hotspots?
- [ ] A. Improperly used secondary index
- [ ] B. Less than optimal partition key
- [x] C. Improperly designed row-key
- [ ] D. Failure to use a read replica

```diff
+ C. The correct answer is C. Hotspots occur when a row-key design does not adequately distribute read/write load for a given query pattern.
- Option A is incorrect; Cloud Bigtable does not have secondary indexes.
- Option B is incorrect; Cloud Bigtable does not use partition keys.
- Options D is incorrect; the hotspots are not caused by failure to use a read replica, although using a read replica may reduce the load on the nodes with hotspots.
```

**2.** An IoT startup has hired you to review their Cloud Bigtable design. The database stores data generated by over 100,000 sensors that send data every 60 seconds. Each row contains all the data for one sensor sent during an hour. Hours always start at the top of the hour. The row-key is the sensor ID concatenated to the hour of the day followed by the date. What change, if any, would you recommend to this design?
- [x] A. Use one row per sensor and 60-second datasets instead of storing multiple datasets in a single row.
- [ ] B. Start the row keyrow-key with the day and hour instead of the sensor ID.
- [ ] C. Allow hours to start an any arbitrary time to accommodate differences in sensor clocks.
- [ ] D. No change is recommended.

```diff
+ A. The correct answer is A. This table should be designed as a tall and narrow one with a single dataset in each row.
- Option B is incorrect because starting a row-key with the date and hour will lead to hotspotting.
- Option C is incorrect, since changing the start time will not change the parts of the design that make querying by ranges more difficult than they need to be.
- Option D is incorrect; the structure of rows should be changed from wide to narrow.
```

**3.** Your company has a Cloud Bigtable database that requires strong consistency, but it also requires high availability. You have implemented Cloud Bigtable replication and specified single-cluster routing in the app profile for the database. Some users have noted that they occasionally receive query results inconsistent with what they should have received. The problem seems to correct itself within a minute. What could be the cause of this problem?
- [ ] A. Secondary indexes are being updated during the query and return incorrect results when a secondary index is not fully updated.
- [x] B. You have not specified an app configuration file that includes single-cluster routing and use of replicas only for failover.
- [ ] C. Tablets are being moved between nodes, which can cause inconsistent query results.
- [ ] D. The row-key is not properly designed.

```diff
+ B. The correct answer is B. The only way to achieve strong consistency in Cloud Bigtable is by having all reads routed from a single cluster and using the other replicas only for failover.
- Option A is incorrect; Cloud Bigtable does not have secondary indexes.
- Option C is incorrect; moving tablets does not impact read consistency.
- Option D is incorrect; a poor row-key design can impact performance but not consistency.
```

**4.** You have been tasked with migrating a MongoDB database to Cloud Spanner. MongoDB is a document database, similar to Cloud Firestore. You would like to maintain some of the document organization of the MongoDB design. What data type, available in Cloud Spanner, would you use to define a column that can hold a document-like structure?
- [ ] A. Array
- [ ] B. String
- [x] C. STRUCT
- [ ] D. JSON

```diff
+ C. The correct answer is C; the STRUCT data type is used to store ordered type fields, and this is the closest to a document structure.
- Option A is incorrect; all elements of an array are of the same data type, but items in a document may consist of different data types.
- Option B is incorrect because although a document could be represented in a string, it does not provide field-level access to data like a STRUCT does.
- Option D is incorrect; JSON is not a valid data type in Cloud Spanner.
```

**5.** An application using a Cloud Spanner database has several queries that are taking longer to execute than the users would like. You review the queries and notice that they all involve joining three or more tables that are all related hierarchically. What feature of Cloud Spanner would you try in order to improve the query performance?
- [ ] A. Replicated clusters
- [x] B. Interleaved tables
- [ ] C. STORING clause
- [ ] D. Execution plans

```diff
+ B. The correct answer is B. Since the problematic queries involved joins of hierarchically related tables, interleaving the data of the tables could improve join performance.
- Option A is incorrect; Cloud Bigtable, not Cloud Spanner, uses replicated clusters.
- Option C is incorrect; the STORING clause is used to create indexes that can answer queries using just the index, and that would not address the join performance problem.
- Option D is incorrect; an execution plan might help you understand the cause of a performance problem, but it would not on its own improve query performance.
```


**6.** A Cloud Spanner database is using a natural key as the primary key for a large table. The natural key is the preferred key by users because the values are easy to relate to other data. Database administrators notice that these keys are causing hotspots on Cloud Spanner nodes and are adversely affecting performance. What would you recommend in order to improve performance?
- [ ] A. Keep the data of the natural key in the table but use a hash of the natural key as the primary key
- [x] B. Keep the natural key and let Cloud Spanner create more splits to improve performance
- [ ] C. Use interleaved tables
- [ ] D. Use more secondary indexes

```diff
+ A. The correct answer is A. By using a hash of the natural key, you will avoid hotspotting and keeping the natural key data in the table will make it available to users.
- Option B is incorrect because Cloud Spanner automatically creates splits based on load, and if the database performance is adversely affected, then splitting is no longer sufficient to address the problem. 
- Option C is incorrect; interleaved tables reduce the number of I/O operations performed when retrieving related data.
- Option D is incorrect; adding more secondary indexes will not change the hotspotting pattern of the primary index.
```

**7.** You are using a UUID as the primary key in a Cloud Spanner database. You have noticed hotspotting that you did not anticipate. What could be the cause?
- [ ] A. You have too many secondary indexes.
- [ ] B. You have too few secondary indexes.
- [x] C. You are using a type of UUID that has sequentially ordered strings at the beginning of the UUID.
- [ ] D. You need to make the maximum length of the primary key longer.

```diff
+ C. The correct answer is C. The likely cause is that you are using a UUID generator that uses time or other sequential values at the start of the key.
- Options A and B are incorrect because secondary indexes are not related to primary key hotspots.
- Option D is incorrect; UUIDs have a fixed, constant length, so the size of the string used to store them should not need to be increased.
```

**8.** You are working for a financial services firm on a Cloud Bigtable database. The database stores equity and bond trading information from approximately 950 customers. Over 10,000 equities and bonds are tracked in the database. New data is received at a rate of 5,000 data points per minute. What general design pattern would you recommend?
- [ ] A. Tall and narrow table
- [ ] B. One table for each customer
- [ ] C. One table for equities and one for bonds
- [ ] D. Option A and Option B
- [x] E. Option A and Option C

```diff
+ E. The correct answer is E. There should be a small number of tall and narrow tables. Option A is incorrect because it does not include one table for equities and one for bonds.
- Option B is incorrect; this would lead to many small tables rather than fewer large tables.
- Option C is incorrect because it is missing the use of tall and narrow tables.
- Option D is incorrect because it includes Option B and not Option C.
```

**9.** You have been brought into a large enterprise to help with a data warehousing initiative. The first project of the initiative is to build a repository for all customer-related data, including sales, finance, inventory, and logistics. It has not yet been determined how the data will be used. What Google Cloud storage system would you recommend that the enterprise use to store that data?
- [ ] A. Cloud Bigtable
- [ ] B. BigQuery
- [ ] C. Cloud Spanner
- [x] D. Cloud Storage

```diff
+ D. The correct answer is D. The enterprise is building a data lake for large volumes of data that is not yet organized for analytics.
- Options A and B are incorrect because there is no information about how data will be queried or what data would be included. 
- Option C is incorrect because Cloud Spanner is a global, horizontally scalable relational database designed for transaction processing.
```

**10.** Data is streaming into a BigQuery table. As the data arrives, it is added to a partition that was automatically created that day. Data that arrives the next day will be written to a different partition. The data modeler did not specify a column to use as a partition key. What kind of partition is being used?
- [x] A. Ingestion time partitioned tables
- [ ] B. Timestamp partitioned tables
- [ ] C. Integer range partitioned tables
- [ ] D. Clustered tables

```diff
+ A. The correct answer is A. Since data is being written to partitions, and the data modeler did not specify a timestamp or integer column as the partition key, it must be partitioned based on ingestion time.
- Options B and C are incorrect because they require a column to be specified that has a partition value.
- Option D is incorrect; clustered tables are not a form of partitioning.
```

**11.** You are designing a BigQuery database with multiple tables in a single dataset. The data stored in the dataset is measurement data from sensors on vehicles in the company’s fleet. Data is collected on each vehicle and downloaded at the end of each shift. After that, it is loaded into a partitioned table. You want to have efficient access to the most interesting data, which you define as a particular measurement having a value greater than 100.00. You want to cluster on that measurement column, which is a FLOAT64. When you define the table with a timestamped partitioned table and clustering on the measurement column, you receive an error. What could that error be?
- [ ] A. You cannot use clustering on an external table.
- [x] B. You cannot use clustering with a FLOAT64 column as the clustering key.
- [ ] C. The table is not the FLOAT64 partition type.
- [ ] D. The clustering key must be an integer or timestamp.

```diff
+ B. The correct answer is B. FLOAT64 is not a supported cluster column type.
- Answer A is incorrect; the table is not external because data is loaded into BigQuery.
- Option C is incorrect; there is no such thing as a FLOAT64 partition type.
- Option D is incorrect; clustering keys do not need to be integers or timestamps—they can be data, Bool, geography, INT64, numeric, string, or timestamp.
```

**12.** What data formats are supported for external tables in Cloud Storage and Google Drive?
- [ ] A. Comma-separated values only
- [ ] B. Comma-separated values and Avro
- [x] C. Comma-separated values, Avro, and newline-delimited JSON
- [ ] D. Comma-separated values, Avro, newline-delimited JSON, and Parquet

```diff
+ C. The correct answer is C; comma-separated values, Avro, and newline-delimited JSON are supported.
- Options A and B are both missing at least one supported format.
- Option D is incorrect because the Parquet format is not supported in Google Drive, although it is supported in Cloud Storage.
```
