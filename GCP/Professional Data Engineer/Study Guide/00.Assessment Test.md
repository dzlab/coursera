# Assessment Test


**1.** You are migrating your machine learning operations to GCP and want to take advantage of managed services. You have been managing a Spark cluster because you use the MLlib library extensively. Which GCP managed service would you use?
- [ ] A. Cloud Dataprep
- [x] B. Cloud Dataproc
- [ ] C. Cloud Dataflow
- [ ] D. Cloud Pub/Sub

```diff
+ B. Cloud Dataproc is a Hadoop and Spark managed service.
- Option A is incorrect; Cloud Dataprep is service for preparing data for analysis.
- Option C is incorrect; Cloud Dataflow is an implementation of Apache Beam, a stream and batch processing service.
- Option D is incorrect; Cloud Pub/Sub is a messaging service that can buffer data in a topic until a service is ready to process the data.
```

**2.** Your team is designing a database to store product catalog information. They have determined that you need to use a database that supports flexible schemas and transactions. What service would you expect to use?
- [ ] A. Cloud SQL
- [ ] B. Cloud BigQuery
- [x] C. Cloud Firestore
- [ ] D. Cloud Storage

```diff
+ C. Cloud Firestore is a managed document database that supports flexible schemas and transactions.
- Option A is incorrect; Cloud SQL does not support flexible schemas.
- Option B is incorrect; BigQuery is an analytical database, not a NoSQL database with a flexible schema.
- Option D is incorrect; Cloud Storage is an object storage system, not a NoSQL database.
```

**3.** Your company has been losing market share because competitors are attracting your customers with a more personalized experience on their e-commerce platforms, including providing recommendations for products that might be of interest to them. The CEO has stated that your company will provide equivalent services within 90 days. What GCP service would you use to help meet this objective?
- [ ] A. Cloud Bigtable
- [ ] B. Cloud Storage
- [x] C. AI Platform
- [ ] D. Cloud Datastore

```diff
+ C. The AI Platform is a managed service for machine learning, which is needed to provide recommendations.
- Options A and B are incorrect because, although they are useful for storing data, they do not provide managed machine learning services.
- Option D is incorrect; Cloud Datastore is a NoSQL database.
```

**4.** The finance department at your company has been archiving data on premises. They no longer want to maintain a costly dedicated storage system. They would like to store up to 300 TB of data for 10 years. The data will likely not be accessed at all. They also want to minimize cost. What storage service would you recommend?
- [ ] A. Cloud Storage multi-regional storage
- [ ] B. Cloud Storage Nearline storage
- [x] C. Cloud Storage Coldline storage
- [ ] D. Cloud Bigtable

```diff
+ C. Cloud Storage Coldline is the lowest-cost option, and it is designed for data that is accessed less than once a year.
- Options A and B are incorrect because they cost more than Coldline storage.
- Option D is incorrect because Cloud Bigtable is a low-latency, wide- column database.
```

**5.** You will be developing machine learning models using sensitive data. Your company has several policies regarding protecting sensitive data, including requiring enhanced security on virtual machines (VMs) processing sensitive data. Which GCP service would you look to for meeting those requirements?
- [ ] A. Identity and access management (IAM)
- [ ] B. Cloud Key Management Service
- [ ] C. Cloud Identity
- [x] D. Shielded VMs

```diff
+ D. Shielded VMs are instances with additional security controls.
- Option A is incorrect; IAM is used for managing identities and authorizations.
- Option B is incorrect; the Cloud Key Management Service is a service for managing encryption keys.
- Option C is incorrect; Cloud Identity is used for authentication.
```

**6.** You have developed a machine learning algorithm for identifying objects in images. Your company has a mobile app that allows users to upload images and get back a list of identified objects. You need to implement the mechanism to detect when a new image is uploaded to Cloud Storage and invoke the model to perform the analysis. Which GCP service would you use for that?
- [x] A. Cloud Functions
- [ ] B. Cloud Storage Nearline
- [ ] C. Cloud Dataflow
- [ ] D. Cloud Dataproc

```diff
+ A. Cloud Functions is a managed serverless product that is able to respond to events in the cloud, such as creating a file in Cloud Storage.
- Option B is incorrect; Cloud Storage Nearline is a class of object storage.
- Option C is incorrect; Cloud Dataflow is a stream and batch processing service that does not respond to events.
- Option D is incorrect; Cloud Dataproc is a managed Hadoop and Spark service.
```

**7.** An IoT system streams data to a Cloud Pub/Sub topic for ingestion, and the data is processed in a Cloud Dataflow pipeline before being written to Cloud Bigtable. Latency is increasing as more data is added, even though nodes are not at maximum utilization. What would you look for first as a possible cause of this problem?
- [ ] A. Too many nodes in the cluster
- [x] B. A poorly designed row key
- [ ] C. Too many column families
- [ ] D. Too many indexes being updated during write operations

```diff
+ B. A poorly designed row key could be causing hot spotting.
- Option A is incorrect; more nodes in a cluster will not increase latency.
- Option C is incorrect; the number of column families on its own would not lead to higher latency.
- Option D is incorrect; Bigtable does not have indexes.
```

**8.** A health and wellness startup in Canada has been more successful than expected. Investors are pushing the founders to expand into new regions outside of North America. The CEO and CTO are discussing the possibility of expanding into Europe. The app offered by the startup collects personal information, storing some locally on the user’s device and some in the cloud. What regulation will the startup need to plan for before expanding into the European market?
- [ ] A. HIPAA
- [ ] B. PCI-DSS
- [x] C. GDPR
- [ ] D. SOX

```diff
+ C. The General Data Protection Regulation (GDPR) is a European Union regulation protecting personal information of persons in and citizens of the European Union. 
- Option A is incorrect; HIPAA is a U.S. healthcare regulation.
- Option B is incorrect; PCI-DSS is a self-imposed global security standard by major brands in the credit card industry, not a government regulation. Although not necessarily law, the standard may be applicable to the start-up in Europe if it accepts payment cards for brands that require PCI-DSS compliance.
- Option D is a U.S. regulation that applies to all publicly traded companies in the United States, and wholly-owned subsidiaries and foreign companies that are publicly traded and do business in the United States - the company may be subject to that regulation already, and expanding to Europe will not change its status.
```

**9.** Your company has been collecting vehicle performance data for the past year and now has 500 TB of data. Analysts at the company want to analyze the data to understand performance differences better across classes of vehicles. The analysts are advanced SQL users, but not all have programming experience. They want to minimize administrative overhead by using a managed service, if possible. What service might you recommend for conducting preliminary analysis of the data?
- [ ] A. Compute Engine
- [ ] B. Kubernetes Engine
- [x] C. BigQuery
- [ ] D. Cloud Functions

```diff
+ C. BigQuery is an analytical database that supports SQL.
- Options A and B are incorrect because, although they could be used for ad hoc analysis, doing so would require more administrative overhead.
- Option D is incorrect; the Cloud Functions feature is intended for running short programs in response to events in GCP.
```

**10.** An airline is moving its luggage-tracking applications to Google Cloud. There are many requirements, including support for SQL and strong consistency. The database will be accessed by users in the United States, Europe, and Asia. The database will store approximately 50 TB in the first year and grow at approximately 10 percent a year after that. What managed database service would you recommend?
- [ ] A. Cloud SQL
- [ ] B. BigQuery
- [x] C. Cloud Spanner
- [ ] D. Cloud Dataflow

```diff
+ C. Cloud Spanner is a globally scalable, strongly consistent relational database that can be queried using SQL.
- Option A is incorrect because it will not scale to the global scale as Cloud Spanner will, and it does not support storing 50 TB of data.
- Option B is incorrect; the requirements call for a transaction processing system, and BigQuery is designed for analytics and data warehousing.
- Option D is incorrect; Cloud Dataflow is a stream and batch processing service.
```

**11.** You are using Cloud Firestore to store data about online game players’ state while in a game. The state information includes health score, a set of possessions, and a list of team members collaborating with the player. You have noticed that the size of the raw data in the database is approximately 2 TB, but the amount of space used by Cloud Firestore is almost 5 TB. What could be causing the need for so much more space?
- [ ] A. The data model has been denormalized.
- [x] B. There are multiple indexes.
- [ ] C. Nodes in the database cluster are misconfigured.
- [ ] D. There are too many column families in use.

```diff
+ B. Cloud Firestore stores data redundantly when multiple indexes are used, so having more indexes will lead to greater storage sizes.
- Option A is incorrect; Cloud Firestore is a NoSQL document database that supports a denormalized data model without using excessive storage.
- Option C is incorrect; you do not configure nodes in Cloud Firestore.
- Option D is incorrect; column families are not used with document databases such as Cloud Firestore.
```

**12.** You have a BigQuery table with data about customer purchases, including the date of purchase, the type of product purchases, the product name, and several other descriptive attributes. There is approximately three years of data. You tend to query data by month and then by customer. You would like to minimize the amount of data scanned. How would you organize the table?
- [x] A. Partition by purchase date and cluster by customer
- [ ] B. Partition by purchase date and cluster by product
- [ ] C. Partition by customer and cluster by product
- [ ] D. Partition by customer and cluster by purchase date

```diff
+ A. Partitioning by purchase date will keep all data for a day in a single partition. Clustering by customer will order the data in a partition by customer. This strategy will minimize the amount of data that needs to be scanned in order to answer a query by purchase date and customer.
- Option B is incorrect; clustering by product does not help reduce the amount of data scanned for date and customer-based queries.
- Option C is incorrect because partitioning by customer is not helpful in reducing the amount of data scanned.
- Option D is incorrect because partitioning by customer would spread data from one date over many partitions, and that would lead to scanning more data than partitioning by purchase date.
```

**13.** You are currently using Java to implement an ELT pipeline in Hadoop. You’d like to replace your Java programs with a managed service in GCP. Which would you use?
- [ ] A. Data Studio
- [x] B. Cloud Dataflow
- [ ] C. Cloud Bigtable
- [ ] D. BigQuery

```diff
+ B. Cloud Dataflow is a stream and batch processing managed service that is a good replacement for Java ELT programs.
- Option A is incorrect; Data Studio is a reporting tool.
- Option C is incorrect; Cloud Bigtable is a NoSQL, wide-column database.
- Option D is incorrect; BigQuery is an analytical database.
```

**14.** A group of attorneys has hired you to help them categorize over a million documents in an intellectual property case. The attorneys need to isolate documents that are relevant to a patent that the plaintiffs argue has been infringed. The attorneys have 50,000 labeled examples of documents, and when the model is evaluated on training data, it performs quite well. However, when evaluated on test data, it performs quite poorly. What would you try to improve the performance?
- [ ] A. Perform feature engineering
- [ ] B. Perform validation testing
- [ ] C. Add more data
- [x] D. Regularization

```diff
+ D. This is a case of the model overfitting the training data. Regularization is a set of methods used to reduce the risk of overfitting.
- Option A is incorrect; feature engineering could be used to create new features if the existing set of features was not sufficient, but that is not a problem in this case.
- Option B is incorrect; validation testing will not improve the quality of the model, but it will measure the quality.
- Option C is incorrect; the existing dataset has a sufficient number of training instances.
```


**15.** Your company is migrating from an on-premises pipeline that uses Apache Kafka for ingesting data and MongoDB for storage. What two managed services would you recommend as replacements for these?
- [ ] A. Cloud Dataflow and Cloud Bigtable
- [ ] B. Cloud Dataprep and Cloud Pub/Sub
- [x] C. Cloud Pub/Sub and Cloud Firestore
- [ ] D. Cloud Pub/Sub and BigQuery

```diff
+ C. Cloud Pub/Sub is a good replacement for Kafka, and Cloud Firestore is a good replacement for MongoDB, which is another document database.
- Option A is incorrect; Cloud Dataflow is for stream and batch processing, not ingestion.
- Option B is incorrect; there is no database in the option.
- Option D is incorrect; BigQuery is analytical database and not a good replacement for a document database such as MongoDB.
```

**16.** A group of data scientists is using Hadoop to store and analyze IoT data. They have decided to use GCP because they are spending too much time managing the Hadoop cluster. They are particularly interested in using services that would allow them to port their models and machine learning workflows to other clouds. What service would you use as a replacement for their existing platform?
- [ ] A. BigQuery
- [ ] B. Cloud Storage
- [x] C. Cloud Dataproc
- [ ] D. Cloud Spanner

```diff
+ C. Cloud Dataproc is a managed Hadoop and Spark service; Spark has a machine learning library called MLlib, and Spark is an open source platform that can run in other clouds.
- Option A is incorrect; BigQuery is a managed data warehouse and analytical database that is not available in other clouds.
- Option B is incorrect; Cloud Storage is used for unstructured data and not a substitute for a Hadoop/Spark platform.
- Option D is incorrect; Cloud Spanner is used for global transaction-processing systems, not large-scale analytics and machine learning.
```

**17.** You are analyzing several datasets and will likely use them to build regression models. You will receive additional datasets, so you’d like to have a workflow to transform the raw data into a form suitable for analysis. You’d also like to work with the data in an interactive manner using Python. What services would you use in GCP?
- [ ] A. Cloud Dataflow and Data Studio
- [x] B. Cloud Dataflow and Cloud Datalab
- [ ] C. Cloud Dataprep and Data Studio
- [ ] D. Cloud Datalab and Data Studio

```diff
+ B. Cloud Dataflow is well suited to transforming batch data, and Cloud Datalab is a Jupyter Notebook managed service, which is useful for ad hoc analysis using Python.
- Options A, B, and C are incorrect. Data Studio is a reporting tool, and that is not needed in this use case.
```

**18.** You have a large number of files that you would like to store for several years. The files will be accessed frequently by users around the world. You decide to store the data in multi-regional Cloud Storage. You want users to be able to view files and their metadata in a Cloud Storage bucket. What role would you assign to those users? (Assume you are practicing the principle of least privilege.)
- [ ] A. roles/storage.objectCreator
- [x] B. roles/storage.objectViewer
- [ ] C. roles/storage.admin
- [ ] D. roles/storage.bucketList

```diff
+ B. The roles/storage.objectViewer role allows users to view objects and list metadata.
- Option A is incorrect; roles/storage.objectCreator allows a user to create an object only.
- Option C is incorrect; the roles/storage.admin role gives a user full control over buckets and objects, which is more privilege than needed.
- Option D is incorrect; there is no such role as roles/storage.bucketList.
```

**19.** You have built a deep learning neural network to perform multiclass classification. You find that the model is overfitting. Which of the following would not be used to reduce overfitting?
- [ ] A. Dropout
- [ ] B. L2 Regularization
- [ ] C. L1 Regularization
- [x] D. Logistic regression

```diff
+ D. Logistic regression is a binary classifier algorithm.
- Options A, B, and C are all regularization techniques.
```

**20.** Your company would like to start experimenting with machine learning, but no one in the company is experienced with ML. Analysts in the marketing department have identified some data in their relational database that they think may be useful for training a model. What would you recommend that they try first to build proof-of-concept models?
- [x] A. AutoML Tables
- [ ] B. Kubeflow
- [ ] C. Cloud Firestore
- [ ] D. Spark MLlib

```diff
+ A. AutoML Tables is a service for generating machine learning models from structured data.
- Option B is incorrect; Kubeflow is an orchestration platform for running machine learning workloads in Kubernetes, which is more than is needed for this use case.
- Option C is incorrect; Cloud Firestore is a document database, not a machine learning service.
- Option D is incorrect because Spark MLlib requires more knowledge of machine learning than AutoML Tables, and therefore it is not as good an option for this use case.
```

**21.** You have several large deep learning networks that you have built using TensorFlow. The models use only standard TensorFlow components. You have been running the models on an n1-highcpu-64 VM, but the models are taking longer to train than you would like. What would you try first to accelerate the model training?
- [ ] A. GPUs
- [x] B. TPUs
- [ ] C. Shielded VMs
- [ ] D. Preemptible VMs

```diff
+ B. TPUs are the correct accelerator because they are designed specifically to accelerate TensorFlow models.
- Option A is incorrect because, although GPUs would accelerate the model training, GPUs are not optimized for the low-precision matrix math that is performed when training deep learning networks.
- Option C is incorrect; shielded VMs have additional security controls, but they do not accelerate model training.
- Option D is incorrect; preemptible machines cost less than non-preemptible machines, but they do not provide acceleration.
```

**22.** Your company wants to build a data lake to store data in its raw form for extended periods of time. The data lake should provide access controls, virtually unlimited storage, and the lowest cost possible. Which GCP service would you suggest?
- [ ] A. Cloud Bigtable
- [ ] B. BigQuery
- [x] C. Cloud Storage
- [ ] D. Cloud Spanner

```diff
+ C. Cloud Storage is an object storage system that meets all of the requirements.
- Option A is incorrect; Cloud Bigtable is a wide-column database.
- Option B is incorrect; BigQuery is an analytical database.
- Option D is incorrect; Cloud Spanner is a horizontally scalable relational database.
```

**23.** Auditors have determined that your company’s processes for storing, processing, and transmitting sensitive data are insufficient. They believe that additional measures must be taken to prevent sensitive information, such as personally identifiable government-issued numbers, are not disclosed. They suggest masking or removing sensitive data before it is transmitted outside the company. What GCP service would you recommend?
- [x] A. Data loss prevention API
- [ ] B. In-transit encryption
- [ ] C. Storing sensitive information in Cloud Key Management
- [ ] D. Cloud Dataflow

```diff
+ A. A data loss prevention API can be used to remove many forms of sensitive data, such as government identifiers.
- Option B is incorrect; encryption can help keep data from being read, but it does not remove or mask sensitive data.
- Option C is incorrect; Cloud Key Management is a service for storing and managing encryption keys.
- Option D is incorrect; Cloud Dataflow is a batch and stream processing service.
```

**24.** You are using Cloud Functions to start the processing of images as they are uploaded into Cloud Storage. In the past, there have been spikes in the number of images uploaded, and many instances of the Cloud Function were created at those times. What can you do to prevent too many instances from starting?
- [ ] A. Use the --max-limit parameter when deploying the function.
- [x] B. Use the --max-instances parameter when deploying the function.
- [ ] C. Configure the --max-instance parameter in the resource hierarchy.
- [ ] D. Nothing. There is no option to limit the number of instances.

```diff
+ B. The --max-instances parameter limits the number of concurrently executing function instances.
- Option A is incorrect; --max-limit is not a parameter used with function deployments.
- Option C is incorrect; there is no --max-instance parameter to set in the resource hierarchy.
- Option D is incorrect; there is a way to specify a limit using the --max-instances parameter.
```

**25.** You have several analysis programs running in production. Sometimes they are failing, but there is no apparent pattern to the failures. You’d like to use a GCP service to record custom information from the programs so that you can better understand what is happening. Which service would you use?
- [ ] A. Stackdriver Debugger
- [x] B. Stackdriver Logging
- [ ] C. Stackdriver Monitoring
- [ ] D. Stackdriver Trace

```diff
+ B. Stackdriver Logging is used to collect semi-structured data about events.
- Option A is incorrect; Stackdriver Debugger is used to inspect the state of running code.
- Option C is incorrect because Stackdriver Monitoring collects performance metrics, not custom data.
- Option D is incorrect; Stackdriver Trace is used to collect information about the time required to execute functions in a call stack.
```

**26.** The CTO of your company is concerned about the rising costs of maintaining your company’s enterprise data warehouse. The current data warehouse runs in a PostgreSQL instance. You would like to migrate to GCP and use a managed service that reduces operational overhead and one that will scale to meet future needs of up to 3 PB. What service would you recommend?
- [ ] A. Cloud SQL using PostgreSQL
- [x] B. BigQuery
- [ ] C. Cloud Bigtable
- [ ] D. Cloud Spanner

```diff
+ B. BigQuery is a managed service that is well suited to data warehousing, and it can scale to petabytes of storage.
- Option A is incorrect; Cloud SQL will not scale to meet future needs.
- Option C is incorrect; Bigtable is a NoSQL, wide-column database, which is not suitable for use with a data warehouse design that uses a relational data model. 
- Option D is incorrect; Cloud Spanner is a transactional, scalable relational database.
```
