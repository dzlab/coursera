# Chapter 5 Building and Operationalizing Processing Infrastructure

## Provisioning and Adjusting Processing Resources

### Provisioning and Adjusting Compute Engine
Compute Engine supports provisioning single instances or groups of instances, known as instance groups. Instance groups are either:
- Managed instance groups (MIGs) consist of identically configured VMs;
- unmanaged instance groups allow for heterogeneous VMs

#### Provisioning Single VM Instances
range of parameters, including the following:

- Machine type, which specifies the number of vCPUs and the amount of memory
- Region and zone to create the VM
- Boot disk parameters
- Network configuration details
- Disk image
- Service account for the VM Metadata and tags

Also,  Shielded VMs for additional secu- rity or GPUs and tensor processing units (TPUs) for additional processing resources.

```sh
gcloud compute instances create instance-1 --zone=us-central1-a --machine-type=n1-standard-1 --subnet=default --network-tier=PREMIUM --image=debian-9-stretch-v20191115 --image-project=debian-cloud --boot-disk-size=10GB --boot-disk-type=pd-standard
```

#### Provisioning Managed Instance Groups
Managed instance groups are managed as a single logical resource. MIGs have several use- ful properties, including:
- Autohealing based on application-specific health checks, which replaces nonfunction- ing instances
- Support for multizone groups that provide for availability in spite of zone-level failures
- Load balancing to distribute workload across all instances in the group
- Autoscaling, which adds or removes instances in the group to accommodate increases and decreases in workloads
- Automatic, incremental updates to reduce disruptions to workload processing

The specifications for a MIG are defined in an instance template, which is a file with VM specifications. Example:
```sh
gcloud compute instance-templates create pde-exam-template-custom \
--machine-type n1-standard-4 \
--image-family debian-9 \
--image-project debian-cloud \
--boot-disk-size 250GB
```
To create an instance from this template
```sh
gcloud compute instances create pde-exam-instance --source-instance-template=pde-exam-template-custom
```

When creating an instance group, you can specify:
- the name of the instance template
- a target CPU utilization that will trigger adding instances to the group up to the maximum number of instances allowed.
- a minimum number of instances.
- the default cooldown period, which is the amount of time GCP will wait before collecting performance statistics from the instance. This gives the instance time to complete startup before its performance is considered for adjusting
the instance group.

#### Adjusting Compute Engine Resources to Meet Demand
One of the advantages of a managed instance group is that the number of VMs in the group can change according to workload. This type of horizontal scaling is readily imple- mented in MIGs because of autoscaling.

An alternative, vertical scaling, requires moving services from one VM to another VM with more or fewer resources.

Many data engineer- ing use cases have workloads that can be distributed across VMs so that horizontal scaling with MIGs is a good option.

If you have a high-performance computing (HPC) workload that must be run on a single server—for example, a monolithic simulation—then you may need to scale VMs vertically.

### Provisioning and Adjusting Kubernetes Engine

#### Provisioning a Kubernetes Engine Cluster
To create a Kubernetes cluster from the command line
```sh
gcloud container clusters create "standard-cluster-1" --zone "us-central1-a" --cluster-version "1.13.11-gke.14" --machine-type "n1-standard-1"
--image-type "COS" --disk-type "pd-standard" --disk-size "100" --num-nodes "5" --enable-autoupgrade --enable-autorepair
```

If a node has sufficient available resources, the scheduler can run the job on that node. You can control where jobs are run using the Kubernetes abstractions known as taints. By assigning taints to node pools and tolerances for taints to pods, you can control when pods are run.

#### Adjusting Kubernetes Engine Resources to Meet Demand
Adjust resources is by scaling applications running in clusters and scaling clusters themselves.

