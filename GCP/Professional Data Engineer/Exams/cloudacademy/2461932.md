# Exam Session

**#10**

What are two of the benefits of using denormalized data structures in BigQuery?
- [ ] It reduces the amount of data processed and increases query speed.
- [ ] It reduces the amount of storage required and increases query speed.
- [x] It increases the query speed and makes queries simpler.
- [ ] It reduces the amount of data processed and reduces the amount of storage required.

**Explanation**:
Denormalization increases query speed for tables with billions of rows because BigQuery's performance degrades when performing joins on large tables, but with a denormalized data structure, you don't have to use joins, since all of the data has been combined into one table. Denormalization also makes queries simpler because you do not have to use join clauses.

Denormalization increases the amount of data processed and the amount of storage required because it creates redundant data.

https://cloud.google.com/solutions/bigquery-data-warehouse#denormalizing_data

Covered in this lecture 

Reducing the Amount of Data Processed
Course: Optimizing Google BigQuery https://cloudacademy.com/course/optimizing-google-bigquery/reducing-the-amount-of-data-processed-1/

**#15**

Which of these statements about BigQuery caching is true?
- [ ] BigQuery caches query results for 48 hours.
- [ ] Query results are cached even if you specify a destination table.
- [x] There is no charge for a query that retrieves its results from cache.
- [ ] By default, a query's results are not cached.

**Explanation**:
When query results are retrieved from a cached results table, you are not charged for the query.

BigQuery caches query results for 24 hours, not 48 hours.

Query results are not cached if you specify a destination table.

A query's results are always cached except under certain conditions, such as if you specify a destination table.

https://cloud.google.com/bigquery/querying-data#query-caching

**#17**

You can customize the software on Dataproc cluster instances in each of the following ways except which one?
- [ ] Log in to the master node and make changes from there
- [ ] Modify configuration files using cluster properties
- [ ] Set initialization actions
- [x] Configure the cluster using Cloud Deployment Manager

**Explanation**

You can access the master node of the cluster by clicking the SSH button next to it in the Cloud Console. 

You can easily use the --properties option of the dataproc command in the Google Cloud SDK to modify many common configuration files when creating a cluster.

When creating a Cloud Dataproc cluster, you can specify initialization actions in executables and/or scripts that Cloud Dataproc will run on all nodes in your Cloud Dataproc cluster immediately after the cluster is set up. [https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/init-actions]

https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/cluster-properties

**#18**

Which Google Cloud Platform service is an alternative to Hadoop with Hive?
- [x] BigQuery
- [ ] Cloud Dataflow
- [ ] Cloud Bigtable
- [ ] Cloud Datastore

**Explanation**

Apache Hive is a data warehouse software project built on top of Apache Hadoop for providing data summarization, query, and analysis.

 
Google BigQuery is an enterprise data warehouse.

https://en.wikipedia.org/wiki/Apache_Hive

**#25**

Which of the following statements is incorrect regarding Bigtable access roles?
- [ ] You can configure access control at the instance and project level.
- [ ] Using IAM roles, you cannot give a user access to only one table in a project, rather than all tables in a project.
- [ ] To give a user access to only one table in a project, you must configure access through your application.
- [x] To give a user access to only one table in a project, grant the user the Bigtable Editor role for that table.

**Explanation**:
For Cloud Bigtable, you can configure access control at the project level. For example, you can grant the ability to:
- Read from, but not write to, any table within the project.
- Read from and write to any table within the project, but not manage instances.
- Read from and write to any table within the project, and manage instances.

https://cloud.google.com/bigtable/docs/access-control

**#31**

The CUSTOM tier for Google AI Platform allows you to specify the number of which types of cluster nodes?
- [ ] Masters, workers, and parameter servers
- [x] Workers and parameter servers
- [ ] Workers
- [ ] Parameter servers

**Explanation**

The CUSTOM tier is not a set tier, but rather enables you to use your own cluster specification. When you use this tier, set values to configure your processing cluster according to these guidelines:
- You must set TrainingInput.masterType to specify the type of machine to use for your master node.
- You may set TrainingInput.workerCount to specify the number of workers to use.
- You may set TrainingInput.parameterServerCount to specify the number of parameter servers to use.

You can specify the type of machine for the master node, but you can't specify more than one master node.

https://cloud.google.com/ai-platform/training/docs/overview#job_configuration_parameters

Covered in this lecture: Scaling

Course: Building Convolutional Neural Networks on Google Cloud

**#32**

When you design a Google Cloud Bigtable schema it is recommended that you _________.
- [ ] Avoid schema designs that are based on NoSQL concepts
- [ ] Create schema designs that are based on a relational database design
- [ ] Create schema designs that require atomicity across rows
- [x] Avoid schema designs that require atomicity across rows

**Explanation**

All operations are atomic at the row level. For example, if you update two rows in a table, it's possible that one row will be updated successfully and the other update will fail. Avoid schema designs that require atomicity across rows.

https://cloud.google.com/bigtable/docs/schema-design#row-keys
