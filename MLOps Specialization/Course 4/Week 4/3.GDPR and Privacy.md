# GDPR and Privacy

## Responsible AI
emerging issues concerning responsible AI and what you as a developer can do to ensure that your models and applications are as responsible as possible.
 
### Responsible AI Practices
The development of AI is creating new opportunities to improve the lives of people around the world from business to health care to education and beyond. But at the same time it's also raising new questions about the best way to build fairness, interpret ability, privacy and security into these systems. These questions are far from solved and are extremely active areas of research and development. I encourage you to commit to following the development of this field and working to make sure that your models and applications are as responsible as you can make them. They will never be perfect, but there is already a lot that you can do with more tools and techniques being developed constantly. 
![image](https://user-images.githubusercontent.com/1645304/134751778-8ccb3d83-9d0c-49f4-9c98-03dab490f687.png)

### Human-centered design

The way actual users experience your system is essential to assessing the true impact of its predictions, recommendations and decisions. For example, you should design your features with appropriate disclosures, built in clarity and control is crucial to a good user experience.

Often it's also a good idea to consider augmentation and assistance, producing a single answer can be appropriate where there is a high probability that the answer satisfies a diversity of users and use cases but in other cases it may be better for your system to suggest a few options to the user. In fact it can even be easier since it's often much more difficult to achieve good precision at one answer top one versus precision and a few answers Maybe top three.

Try to plan for modeling potential adverse feedback early in the design process followed by specific live testing and iteration for a small fraction of traffic before full deployment.

And finally engage with a diverse set of users and different use case scenarios and incorporate that feedback both before and throughout your project development. This will build a rich variety of user's perspectives into the project and increase the number of people who benefit from the technology and help you catch potential issues early.

![image](https://user-images.githubusercontent.com/1645304/134751901-326e2a7c-d30e-4629-818c-c86e4c582a5c.png)

### Identify Multiple Metrics

A fairly simple technique is to use several metrics rather than a single one, which can help you understand trade offs between different kinds of errors and experiences.
Consider metrics including:
- feedback from users surveys,
- quantities that track overall system performance,

Also short and long term product health for example,
- click through rate and
- customer lifetime value respectively and
- false positive and false negative rates sliced across different subgroups.

Of course the metrics that you select are important, you should try to ensure that your metrics are appropriate for the context and goals of your system. For example, a fire alarm system should have high recall even if that means the occasional false alarm.

![image](https://user-images.githubusercontent.com/1645304/134752218-da442fe2-d9cf-4ec8-8344-9e207f45e23c.png)


### Analyze your raw data carefully

Of course, as always it all comes back to the data ML models will reflect the data that they're trained on. So analyze your raw data carefully to ensure you understand it in cases where this is not possible.

For example with sensitive raw data, understand your input data as much as possible while respecting privacy. For example, by computing aggregate anonymized summaries, consider whether your data was sampled in a way that represents your users. For example, if your application will be used by people of all ages, but you only have training data from senior citizens, it might not work that well for other age groups.

Imagine doing music recommendations when all of your data is from senior citizens. My guess is that it might not perform that well for tweens, sometimes you're using your model to predict a proxy label for the actual target that you're interested in because labelling for the actual target is difficult or impossible. In these cases consider the relationship between the data labels that you have and the actual thing that you're trying to predict.

Are there problematic gaps? For example, if you're using data label X as a proxy to predict target Y, in which case is is the gap between X and Y problematic.


![image](https://user-images.githubusercontent.com/1645304/134752380-a98c087f-29d1-4841-ab2b-43041cdea78f.png)

## Reading: Responsible AI
New technologies always bring new challenges. Ensuring that your applications adhere to responsible AI is a must. Please read this [resource](https://ai.google/responsibilities/responsible-ai-practices/) to keep yourself updated with this fascinating active research  subject.

## Legal Requirements for Secure and Private AI
A legal side to practicing responsible AI. They are already a legal requirements in some countries and regions, and this trend is growing. Exposure to civil liability is another concern.

### Legal Implications of Data Security and Privacy
Training data, prediction requests, or both, can contain very sensitive information about people. For prediction request, those people are your users.

Privacy of sensitive data should be protected:
- This includes not only respecting the legal and regulatory requirements,
- but also considering social norms and typical individual expectations.

What safeguards do you need to put in place to ensure the privacy of individuals considering that ML models may remember or reveal aspects of the data that they've been exposed to?

What steps are needed to ensure users have adequate transparency and control of their data?

It's not just up to you to decide what is required:
- In Europe, for example, you need to comply with the General Data Protection Regulations, or GDPR, and
- in California, you need to comply with the California Consumer Privacy Act, or CCPA.

![image](https://user-images.githubusercontent.com/1645304/134752516-4dd8dbea-ecd5-45af-9312-e1a3aa2c363f.png)

### General Data Protection Regulation (GDPR)
The General Data Protection Regulation, or GDPR, was enacted by the EU in 2016 and became a model for many national laws outside the EU, including Chile, Japan, Brazil, South Korea, Argentina, and Kenya. It regulates the data protection and privacy in the European Union and the European Economic Area.

The GDPR gives individuals control over their personal data and requires that companies should protect the data of employees and consumers.

When data processing is based on consent, the data subject, usually an individual person, has the right to revoke their consent at any time.

![image](https://user-images.githubusercontent.com/1645304/134752611-420a76f8-1fb3-49c4-a9a0-e752cf7dd4be.png)

### California Consumer Privacy Act (CCPA)
In California, Consumer Privacy Act, or CCPA, was modeled after the GDPR and has similar goals, including:
- enhancing the privacy rights and
- consumer protections for residents of California.

It states that users have the right to know:
- what personal data is being collected about them, including whether the personal data is sold or disclosed in some way,
- who supplied their data and
- who received their data.

Users can access the personal data which a company has for them, block the sale of their data, and request a business to delete their data.

![image](https://user-images.githubusercontent.com/1645304/134752676-604b54e7-ebc7-42f1-b24a-fe4bfd72bd4a.png)

### Securit and Privacy Harms from ML Models
